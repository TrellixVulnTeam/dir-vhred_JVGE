Configurations
{'activation': 'Tanh',
 'batch_size': 40,
 'beam_size': 1,
 'bidirectional': True,
 'bow': False,
 'checkpoint': None,
 'clip': 1.0,
 'context_size': 1000,
 'conversation_length_path': PosixPath('/home/992324409_m/notespace/AHLSVAE_diri/datasets/ubuntu/train/conversation_length.pkl'),
 'data': 'ubuntu',
 'data_dir': PosixPath('/home/992324409_m/notespace/AHLSVAE_diri/datasets/ubuntu/train'),
 'dataset_dir': PosixPath('/home/992324409_m/notespace/AHLSVAE_diri/datasets/ubuntu'),
 'decoder_hidden_size': 1000,
 'dropout': 0.2,
 'embedding_size': 500,
 'encoder_hidden_size': 1000,
 'eval_batch_size': 80,
 'feedforward': 'FeedForward',
 'id2word_path': PosixPath('/home/992324409_m/notespace/AHLSVAE_diri/datasets/ubuntu/id2word.pkl'),
 'importance_sample': 100,
 'kl_annealing_iter': 250000,
 'kl_threshold': 0.0,
 'learning_rate': 0.0001,
 'logdir': PosixPath('/data2/992324409_m/conversation/ubuntu/VHRED/2019-01-16_01:10:39'),
 'max_unroll': 30,
 'mode': 'train',
 'model': 'VHRED',
 'n_context': 1,
 'n_epoch': 30,
 'n_sample_step': 1,
 'num_layers': 1,
 'optimizer': <class 'torch.optim.adam.Adam'>,
 'plot_every_epoch': 1,
 'print_every': 100,
 'rnn': <class 'torch.nn.modules.rnn.GRU'>,
 'rnncell': <class 'layers.rnncells.StackedGRUCell'>,
 'sample': False,
 'save_every_epoch': 1,
 'save_path': PosixPath('/data2/992324409_m/conversation/ubuntu/VHRED/2019-01-16_01:10:39'),
 'sentence_drop': 0.0,
 'sentence_length_path': PosixPath('/home/992324409_m/notespace/AHLSVAE_diri/datasets/ubuntu/train/sentence_length.pkl'),
 'sentences_path': PosixPath('/home/992324409_m/notespace/AHLSVAE_diri/datasets/ubuntu/train/sentences.pkl'),
 'temperature': 1.0,
 'tie_embedding': True,
 'word2id_path': PosixPath('/home/992324409_m/notespace/AHLSVAE_diri/datasets/ubuntu/word2id.pkl'),
 'word_drop': 0.0,
 'z_conv_size': 100,
 'z_sent_size': 100}
Loading Vocabulary...
Vocabulary size: 20000
Traceback (most recent call last):
  File "train.py", line 29, in <module>
    sentences=load_pickle(config.sentences_path),
  File "train.py", line 11, in load_pickle
    return pickle.load(f)
KeyboardInterrupt
